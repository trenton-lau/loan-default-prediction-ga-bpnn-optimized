{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fba2755-82e4-4f63-9c6d-f1350acebb7a",
   "metadata": {},
   "source": [
    "# import and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0582eda3-ee69-442e-9fcb-7f01af908b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "train = pd.read_csv('Wilson_train.csv', low_memory = False, index_col = False)\n",
    "test = pd.read_csv('Wilson_test.csv', low_memory = False, index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2bb5f5-1742-409e-a3fc-e5216d1b4f85",
   "metadata": {},
   "source": [
    "# (training) cleaning null and strange value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94192cc9-4ab7-4ae9-befd-64198478f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 2 3 8 9 25\n",
    "train = train.dropna()\n",
    "\n",
    "# column 2 (only for training data)\n",
    "train = train[train['Date_Of_Disbursement'].str.len() < 10]\n",
    "\n",
    "# column 3\n",
    "train = train[(train.iloc[:, 2] != '0')]\n",
    "\n",
    "# column 6 (only for training data)\n",
    "train.iloc[:, 5] = train.iloc[:, 5].str[:4]\n",
    "train['Year_Of_Commitment '] = pd.to_numeric(train['Year_Of_Commitment '])\n",
    "\n",
    "# column 7\n",
    "train.iloc[:, 6] = train.iloc[:, 6].str[3:]\n",
    "train['Guaranteed_Approved _Loan'] = pd.to_numeric(train['Guaranteed_Approved _Loan'])\n",
    "\n",
    "# column 9\n",
    "train = train[(train['Low_Documentation_Loan'] == 'Yes') | (train['Low_Documentation_Loan'] == 'No')]\n",
    "\n",
    "# column 12\n",
    "train.iloc[:, 11] = train.iloc[:, 11].str[3:]\n",
    "train['ChargedOff_Amount '] = pd.to_numeric(train['ChargedOff_Amount '])\n",
    "\n",
    "# column 18\n",
    "train.iloc[:, 17] = train.iloc[:, 17].str[3:]\n",
    "train['Loan_Approved_Gross'] = pd.to_numeric(train['Loan_Approved_Gross'])\n",
    "\n",
    "# column 19\n",
    "train.iloc[:, 18] = train.iloc[:, 18].str[3:]\n",
    "train['Gross_Amount_Disbursed  '] = pd.to_numeric(train['Gross_Amount_Disbursed  '])\n",
    "\n",
    "# column 23\n",
    "train.iloc[:, 22] = train.iloc[:, 22] > 0\n",
    "train['Code_Franchise'] = train['Code_Franchise']*1\n",
    "\n",
    "# column 25\n",
    "train['Revolving_Credit_Line'] = train['Revolving_Credit_Line'].str.replace('0' , 'No')\n",
    "train['Revolving_Credit_Line'] = train['Revolving_Credit_Line'].str.replace('1' , 'Yes')\n",
    "train['Revolving_Credit_Line'] = train['Revolving_Credit_Line'].str.replace('T' , 'Yes')\n",
    "train = train[(train['Revolving_Credit_Line'] == 'Yes') | (train['Revolving_Credit_Line'] == 'No')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa1b7f-9063-4e23-bbfc-00eb00400467",
   "metadata": {},
   "source": [
    "# (training) new column: day difference = disbursement date - commitment date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7be8f32-554f-48c3-abf7-407814c00986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for date difference\n",
    "def days_difference(d1, d2):\n",
    "    d1 = datetime.strptime(d1, '%d-%b-%y')\n",
    "    d2 = datetime.strptime(d2, '%d-%b-%y')\n",
    "    return abs((d2 - d1).days)\n",
    "\n",
    "# creating new variable days difference\n",
    "days_diff_train = [None]*train.shape[0]\n",
    "for i in range(0, train.shape[0]):\n",
    "    commit_date = train['Commitment_Date'].iloc[i]\n",
    "    disburse_date = train['Date_Of_Disbursement'].iloc[i]\n",
    "    days_diff_train[i] = days_difference(commit_date, disburse_date)\n",
    "\n",
    "# add the new column to the original dataset\n",
    "train['Days_Difference'] = days_diff_train\n",
    "columns = list(train.columns)\n",
    "columns[-2], columns[-1] = columns[-1], columns[-2]\n",
    "train = train[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddddf0-0cbd-4df3-b64d-59f86c2d9225",
   "metadata": {},
   "source": [
    "# (training) converting categorical variable to numeric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9482f1-68b0-4906-b886-b24581523042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'Date_Of_Disbursement' to days since the earliest\n",
    "train['Date_Of_Disbursement'] = pd.to_datetime(train['Date_Of_Disbursement'], format='%d-%b-%y')\n",
    "earliest_date = train['Date_Of_Disbursement'].min()\n",
    "train['Date_Of_Disbursement'] = (train['Date_Of_Disbursement'] - earliest_date).dt.days\n",
    "\n",
    "# convert 'Business' to categorical variable\n",
    "train['Business'] = pd.Categorical(train['Business'])\n",
    "\n",
    "# convert 'Low_Documentation_Loan' to categorical variable\n",
    "train['Low_Documentation_Loan'] = pd.Categorical(train['Low_Documentation_Loan'])\n",
    "\n",
    "# convert 'Demography' to categorical variable\n",
    "train['Demography'] = pd.Categorical(train['Demography'])\n",
    "\n",
    "# convert 'State_Of_Bank' to categorical variable\n",
    "train['State_Of_Bank'] = pd.Categorical(train['State_Of_Bank'])\n",
    "\n",
    "# convert 'Borrower_State' to categorical variable\n",
    "train['Borrower_State'] = pd.Categorical(train['Borrower_State'])\n",
    "\n",
    "# convert 'Commitment_Date' to days since the earliest\n",
    "train['Commitment_Date'] = pd.to_datetime(train['Commitment_Date'], format='%d-%b-%y')\n",
    "earliest_date = train['Commitment_Date'].min()\n",
    "train['Commitment_Date'] = (train['Commitment_Date'] - earliest_date).dt.days\n",
    "\n",
    "# convert 'Revolving_Credit_Line' to categorical variable\n",
    "train['Revolving_Credit_Line'] = pd.Categorical(train['Revolving_Credit_Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074a23f-719e-43ac-8b7d-ed3b25acd8d5",
   "metadata": {},
   "source": [
    "# (training) discard unwanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd34c4bb-f91f-4d1d-91e7-280166f9be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "train = train.drop(['ID', 'Borrower_Name ', 'Borrower_City', 'Gross_Amount_Balance', \n",
    "                    'Classification_Code ', 'Primary_Loan_Digit', 'Name_Of_Bank'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d40ad-14de-4aa3-88b0-4beb6a684ab8",
   "metadata": {},
   "source": [
    "# (testing) managing null and strange value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d19aba0-903f-4f91-85c4-c45037f06f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 7\n",
    "test.iloc[:, 6] = test.iloc[:, 6].str[3:]\n",
    "test['Guaranteed_Approved _Loan'] = pd.to_numeric(test['Guaranteed_Approved _Loan'])\n",
    "\n",
    "# column 12\n",
    "test.iloc[:, 11] = test.iloc[:, 11].str[3:]\n",
    "test['ChargedOff_Amount '] = pd.to_numeric(test['ChargedOff_Amount '])\n",
    "\n",
    "# column 18\n",
    "test.iloc[:, 17] = test.iloc[:, 17].str[3:]\n",
    "test['Loan_Approved_Gross'] = pd.to_numeric(test['Loan_Approved_Gross'])\n",
    "\n",
    "# column 19\n",
    "test.iloc[:, 18] = test.iloc[:, 18].str[3:]\n",
    "test['Gross_Amount_Disbursed  '] = pd.to_numeric(test['Gross_Amount_Disbursed  '])\n",
    "\n",
    "# column 23\n",
    "test.iloc[:, 22] = test.iloc[:, 22] > 0\n",
    "test['Code_Franchise'] = test['Code_Franchise']*1\n",
    "\n",
    "# column 25\n",
    "test['Revolving_Credit_Line'] = test['Revolving_Credit_Line'].str.replace('0' , 'No')\n",
    "test['Revolving_Credit_Line'] = test['Revolving_Credit_Line'].str.replace('1' , 'Yes')\n",
    "test['Revolving_Credit_Line'] = test['Revolving_Credit_Line'].str.replace('T' , 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171f883-eed6-43d7-9963-97a4880447b7",
   "metadata": {},
   "source": [
    "# (testing) new column: day difference = disbursement date - commitment date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74f5b848-cabd-4651-804f-a4550736da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for date difference\n",
    "def days_difference(d1, d2):\n",
    "    try:\n",
    "        if isinstance(d1, float):\n",
    "            d1 = datetime.fromordinal(int(d1))\n",
    "        else:\n",
    "            d1 = datetime.strptime(str(d1), '%d-%b-%y')\n",
    "        if isinstance(d2, float):\n",
    "            d2 = datetime.fromordinal(int(d2))\n",
    "        else:\n",
    "            d2 = datetime.strptime(str(d2), '%d-%b-%y')\n",
    "        return abs((d2 - d1).days)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# creating new variable days difference\n",
    "days_diff_test = [None]*test.shape[0]\n",
    "for i in range(0, test.shape[0]):\n",
    "    commit_date = test['Commitment_Date'].iloc[i]\n",
    "    disburse_date = test['Date_Of_Disbursement'].iloc[i]\n",
    "    days_diff_test[i] = days_difference(commit_date, disburse_date)\n",
    "\n",
    "# add the new column to the original dataset\n",
    "test['Days_Difference'] = days_diff_test\n",
    "columns = list(test.columns)\n",
    "columns[-2], columns[-1] = columns[-1], columns[-2]\n",
    "test = test[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a905bb0-4544-46ac-b851-1242abaee81a",
   "metadata": {},
   "source": [
    "# (testing) converting categorical variable to numeric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe117285-ccbe-4d1a-8b09-27bfb0b0f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'Date_Of_Disbursement' to days since the earliest\n",
    "test['Date_Of_Disbursement'] = pd.to_datetime(test['Date_Of_Disbursement'], format='%d-%b-%y')\n",
    "earliest_date = test['Date_Of_Disbursement'].min()\n",
    "test['Date_Of_Disbursement'] = (test['Date_Of_Disbursement'] - earliest_date).dt.days\n",
    "\n",
    "# convert 'Business' to categorical variable\n",
    "test['Business'] = pd.Categorical(test['Business'])\n",
    "\n",
    "# convert 'Low_Documentation_Loan' to categorical variable\n",
    "test['Low_Documentation_Loan'] = pd.Categorical(test['Low_Documentation_Loan'])\n",
    "\n",
    "# convert 'Demography' to categorical variable\n",
    "test['Demography'] = pd.Categorical(test['Demography'])\n",
    "\n",
    "# convert 'State_Of_Bank' to categorical variable\n",
    "test['State_Of_Bank'] = pd.Categorical(test['State_Of_Bank'])\n",
    "\n",
    "# convert 'Borrower_State' to categorical variable\n",
    "test['Borrower_State'] = pd.Categorical(test['Borrower_State'])\n",
    "\n",
    "# convert 'Commitment_Date' to days since the earliest\n",
    "test['Commitment_Date'] = pd.to_datetime(test['Commitment_Date'], format='%d-%b-%y')\n",
    "earliest_date = test['Commitment_Date'].min()\n",
    "test['Commitment_Date'] = (test['Commitment_Date'] - earliest_date).dt.days\n",
    "\n",
    "# convert 'Revolving_Credit_Line' to categorical variable\n",
    "test['Revolving_Credit_Line'] = pd.Categorical(test['Revolving_Credit_Line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071568fd-0dc2-4971-befc-47a90bf83e37",
   "metadata": {},
   "source": [
    "# (testing) discard unwanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99ecc62-2f49-4d57-b652-925ad698af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "test = test.drop(['ID', 'Borrower_Name ', 'Borrower_City', 'Gross_Amount_Balance', \n",
    "                    'Classification_Code ', 'Primary_Loan_Digit', 'Name_Of_Bank'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ce1bd-1294-481e-941e-098d4a6d1e2e",
   "metadata": {},
   "source": [
    "# GA-BPNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db3a8994-7ee5-47ab-b7ca-d937258a443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0: Max = 0.9865, Avg = 0.9853, Std = 0.0005\n",
      "Gen 1: Max = 0.9866, Avg = 0.9858, Std = 0.0004\n",
      "Gen 2: Max = 0.9868, Avg = 0.9861, Std = 0.0004\n",
      "Gen 3: Max = 0.9868, Avg = 0.9864, Std = 0.0004\n",
      "Gen 4: Max = 0.9868, Avg = 0.9866, Std = 0.0002\n",
      "Gen 5: Max = 0.9871, Avg = 0.9867, Std = 0.0003\n",
      "Gen 6: Max = 0.9871, Avg = 0.9868, Std = 0.0003\n",
      "Gen 7: Max = 0.9871, Avg = 0.9870, Std = 0.0002\n",
      "Gen 8: Max = 0.9871, Avg = 0.9871, Std = 0.0001\n",
      "Gen 9: Max = 0.9871, Avg = 0.9871, Std = 0.0000\n",
      "\n",
      "Best hidden layer sizes: [14, 64, 7]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15161\n",
      "           1       0.98      0.99      0.99      5839\n",
      "\n",
      "    accuracy                           0.99     21000\n",
      "   macro avg       0.99      0.99      0.99     21000\n",
      "weighted avg       0.99      0.99      0.99     21000\n",
      "\n",
      "\n",
      "F1 Score: 0.9870704321197686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# 1. Data Preparation\n",
    "\n",
    "# Define feature columns\n",
    "numeric_features = ['Jobs_Reatained', 'Jobs_Created ', 'Year_Of_Commitment ', 'Guaranteed_Approved _Loan',\n",
    "                    'ChargedOff_Amount ', 'Count_Employees', 'Loan_Approved_Gross', 'Gross_Amount_Disbursed  ',\n",
    "                    'Loan_Term', 'Code_Franchise', 'Days_Difference']\n",
    "\n",
    "categorical_features = ['Business', 'Low_Documentation_Loan', 'Demography', 'State_Of_Bank', 'Borrower_State',\n",
    "                        'Revolving_Credit_Line']\n",
    "\n",
    "date_features = ['Date_Of_Disbursement', 'Commitment_Date']\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Convert date features to numeric (number of days since a reference date)\n",
    "reference_date = pd.to_datetime('1970-01-01')\n",
    "\n",
    "for date_col in date_features:\n",
    "    train[date_col] = pd.to_datetime(train[date_col])\n",
    "    test[date_col] = pd.to_datetime(test[date_col])\n",
    "    \n",
    "    train[f'{date_col}_days'] = (train[date_col] - reference_date).dt.days\n",
    "    test[f'{date_col}_days'] = (test[date_col] - reference_date).dt.days\n",
    "    \n",
    "    numeric_features.append(f'{date_col}_days')\n",
    "\n",
    "# Prepare the data\n",
    "X_train = preprocessor.fit_transform(train)\n",
    "X_test = preprocessor.transform(test)\n",
    "\n",
    "y_train = train['Default'].values\n",
    "y_test = test['Default'].values\n",
    "\n",
    "# 2. Define GA-BPNN\n",
    "\n",
    "def create_mlp(hidden_layer_sizes):\n",
    "    return MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                         max_iter=1000,\n",
    "                         early_stopping=True,\n",
    "                         random_state=42)\n",
    "\n",
    "def evaluate_mlp(hidden_layer_sizes):\n",
    "    mlp = create_mlp(hidden_layer_sizes)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    return f1_score(y_test, y_pred),\n",
    "\n",
    "# Setup genetic algorithm\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_int\", random.randint, 1, 100)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, n=3)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate_mlp)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=100, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# 3. Run Genetic Algorithm with progress tracking\n",
    "def print_stats(gen, population, fits):\n",
    "    length = len(population)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "    print(f\"Gen {gen}: Max = {max(fits):.4f}, Avg = {mean:.4f}, Std = {std:.4f}\")\n",
    "\n",
    "population = toolbox.population(n=50)\n",
    "ngen = 10\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"max\", max)\n",
    "\n",
    "for gen in range(ngen):\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
    "    fits = toolbox.map(toolbox.evaluate, offspring)\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    population = toolbox.select(offspring, k=len(population))\n",
    "    record = stats.compile(population)\n",
    "    print_stats(gen, population, [ind.fitness.values[0] for ind in population])\n",
    "\n",
    "# Get the best individual\n",
    "best_ind = tools.selBest(population, k=1)[0]\n",
    "print(f\"\\nBest hidden layer sizes: {best_ind}\")\n",
    "\n",
    "# 4. Train and evaluate the best model\n",
    "best_mlp = create_mlp(best_ind)\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Handle missing values in test set\n",
    "X_test_clean = np.nan_to_num(X_test, nan=0)  # Replace NaN with 0\n",
    "\n",
    "y_pred = best_mlp.predict(X_test_clean)\n",
    "\n",
    "# 5. Print results\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nF1 Score:\", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
